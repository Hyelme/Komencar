# Object Detection API(Tensorflow1 ver.)

## â­ì°¸ê³ â­

- ì•„ë‚˜ì½˜ë‹¤ ëª…ë ¹ì–´

[íŒŒì´ì¬ conda ë° pip ëª…ë ¹ì–´](https://dowtech.tistory.com/14)

# 1. Anaconda í™˜ê²½ êµ¬ì¶•

> ì´ë¦„ : Object-Detection
python ë²„ì „ : 3.7.10

```powershell
conda create -n Object-Detection python=3.7
```

  

### ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¦¬ìŠ¤íŠ¸

> **conda**(ë˜ëŠ” pip) **install** **'ë¼ì´ë¸ŒëŸ¬ë¦¬ëª…'**(==ë²„ì „)

```
numpy 1.18.5
tensorflow-gpu 1.15.5 [pip install tensorflow-gpu==1.14]
cython 0.29.22
git 2.23.0 [conda install git -y]
pycocotools 2.0 [pip install git+https://github.com/philferriere/cocoapi.git#subdirectory=PythonAPI]

// GPUë¥¼ ì‚¬ìš©í•˜ê¸° ìœ„í•´ì„œ ê¼­ ì„¤ì¹˜
CUDA toolkit : 10.0.130
CuDNN : 7.6.5
```

```powershell
// cuda toolkit
conda install cudatoolkit=10.0.130

//cudnn
conda install cudnn==7.6.5
```

- tensorflow ë²„ì „ì— ë§ëŠ” cudatoolkit, cudnn ë²„ì „ í™•ì¸

[Build from source on Windows | TensorFlow](https://www.tensorflow.org/install/source_windows#tested_build_configurations)

- tensorflow ì‘ë™ í™•ì¸í•˜ê¸°

```powershell
python -c "import tensorflow as tf;print(tf.reduce_sum(tf.random.normal([1000, 1000])))"
```

  

# 2. Tensorflow Object Detection API ë‹¤ìš´ë¡œë“œ ë° ì»´íŒŒì¼í•˜ê¸°

> APIë¥¼ ì„¤ì¹˜í•˜ê³  ê°€ìƒí™˜ê²½ì— ì ìš©ì‹œí‚¤ëŠ” ë‹¨ê³„

```powershell
[apië¥¼ ì €ì¥í•  ê²½ë¡œ]>
git clone https://github.com/tensorflow/models.git 
```

- Protobuf ì„¤ì¹˜ ë° ì»´íŒŒì¼

Protobuf : Protocol Bufferë¼ê³  í•˜ëŠ” ì§ë ¬í™” ë°ì´í„°êµ¬ì¡°ë¥¼ ë„ëŠ” ê²ƒ

â‡’ ë°ì´í„° ì €ì¥ ë°©ì‹ì„ ë³€ê²½í•¨ìœ¼ë¡œì¨ ìš©ëŸ‰ì—ì„œ ì´ë“ì„ ë³¼ ìˆ˜ ìˆë‹¤.

â‡’ Tensorflow Object Detection APIëŠ” ëª¨ë¸ê³¼ í•™ìŠµ íŒŒë¼ë¯¸í„°ë“¤ì„ ì´ëŸ¬í•œ ë°©ì‹ìœ¼ë¡œ êµ¬ì„±í–ˆìœ¼ë¯€ë¡œ ì»´íŒŒì¼ ì—­ì‹œ Protobuf ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ ì§„í–‰í•´ì•¼ í•œë‹¤.

```
Protobuf ë²„ì „ : 3.14.0 (protoc-3.14.0-win64.zip ë‹¤ìš´)  
```

  

- zip íŒŒì¼ ë‹¤ìš´ ê²½ë¡œ

[Releases Â· protocolbuffers/protobuf](https://github.com/protocolbuffers/protobuf/releases)

- ì••ì¶• í•´ì œ í›„, proto.exe íŒŒì¼ì´ ì¡´ì¬í•˜ëŠ” ê²½ë¡œ(~\bin)ë¥¼ ì‹œìŠ¤í…œ í™˜ê²½ ë³€ìˆ˜ì— ì¶”ê°€
- protoc ì‚¬ìš© ì—¬ë¶€ í™•ì¸(í™•ì¸ ê²½ë¡œ : ~\models\research)

```
protoc object_detection/protos/*.proto --python_out=.
```

![README_assets/Untitled.png](README_assets/Untitled.png)

protoc ì»´íŒŒì¼ ì™„ë£Œ í™”ë©´  



# 3. COCO API ì„¤ì¹˜(Optional)

- Tensorflow 2.x ë²„ì „ Object Detection APIë¥¼ ì„¤ì¹˜í•  ë•Œ pycocotoolsê°€ í•¨ê»˜ ì„¤ì¹˜ë˜ì§€ë§Œ ë‹¤ì–‘í•œ ì´ìœ ë¡œ ë²„ê·¸ê°€ ìƒê¸¸ ìˆ˜ ìˆë‹¤.
- ê±´ë„ˆë›°ì–´ë„ ë˜ì§€ë§Œ ë¯¸ë¦¬ ì„¤ì¹˜í• êº¼ë©´ ì´ëŒ€ë¡œ í•˜ë©´ ë¨

```
[~\models\research]>
pip install cython //cython ì„¤ì¹˜
conda install git -y //git ì„¤ì¹˜
//pycocotools ì„¤ì¹˜
pip install git+https://github.com/philferriere/cocoapi.git#subdirectory=PythonAPI
```

  

**â—ì˜¤ë¥˜ ì´ìŠˆâ—**

- pycocotools ì„¤ì¹˜ ì¤‘ Microsoft Visual C++14.0 is required. ì˜¤ë¥˜ ë°œìƒ

    â‡’ ì•„ë˜ì˜ í™ˆí˜ì´ì§€ì—ì„œ **ì¬ë°°í¬ ê°€ëŠ¥ íŒ¨í‚¤ì§€ ë° ë¹Œë“œ ë„êµ¬ > Microsoft Build Tools 2015 ì—…ë°ì´íŠ¸ 3** ë‹¤ìš´ë¡œë“œ í•´ì„œ ê¸°ë³¸ê°’ìœ¼ë¡œ ì„¤ì¹˜

    [Visual Studio Older Downloads - 2017, 2015 & Previous Versions](https://visualstudio.microsoft.com/ko/vs/older-downloads/)  
    
    

# 4. Tensorflow Object Detection API ì„¤ì¹˜

- ~\models\researchì— setup.py íŒŒì¼ ë³µì‚¬

```
[~\models\research]>
cp object_detection/packages/tf1/setup.py .
```

- ìœˆë„ìš° anacondaì—ì„œëŠ” cp ëª…ë ¹ì–´ê°€ ì‹¤í–‰ë˜ì§€ ì•Šì„ ìˆ˜ ìˆë‹¤.

    â‡’ **[models/research/object_detection/packages/tf1/]** ê²½ë¡œë¡œ ì§ì ‘ ë“¤ì–´ê°€ setup.py íŒŒì¼ì„ **[models/research]**ì— ë³µì‚¬

```
[~\models\research]>
python -m pip install .
```

  

**â—ì´ìŠˆâ—**

- setup.py ë¥¼ ì„¤ì¹˜í–ˆë”ë‹ˆ numpy ë²„ì „ì´ 1.19.5ë¡œ ë°”ë€Œë©´ì„œ ì¶©ëŒë‚¨

    â‡’ pip uninstall numpy í•´ì£¼ê³  conda install numpy==1.18.5ë¡œ ë‹¤ì‹œ ì„¤ì¹˜

- tensorflowë‘ tensorflow-gpuë‘ ê°™ì´ ì„¤ì¹˜ë˜ì–´ìˆìœ¼ë©´ ì¶©ëŒë‚œë‹¤ë˜ë° ì´ê±´ ì½”ë“œ ì‹¤í–‰í•´ë³´ë©´ì„œ í™•ì¸í•´ì•¼í• êº¼ ê°™ìŒ  

    

# 5. 1~4ê¹Œì§€ ì„¤ì¹˜ ì˜ ëëŠ”ì§€ í™•ì¸

```
[~models\research]>
python object_detection/builders/model_builder_tf1_test.py
```

- ìœ„ì˜ ëª…ë ¹ì–´ ì…ë ¥ ì‹œ, ë‹¤ìŒê³¼ ê°™ì´ ì¶œë ¥ë˜ë©´ ì„±ê³µ

![README_assets/Untitled%201.png](README_assets/Untitled%201.png)

  

# 6-1. Tensorflow Object Detection API tutorial ë”°ë¼í•˜ê¸°

**â­ê³µí™ˆ ë”°ë¼í•˜ê¸°â­**

[TensorFlow 2 Object Detection API tutorial - TensorFlow 2 Object Detection API tutorial documentation](https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/tensorflow-1.14/)

  

### 1. í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¶”ê°€ ì„¤ì¹˜

```jsx
opencv 3.4.2
pathlib 1.0.1
```

  

### 2. Tensorflow model ë‹¤ìš´ë¡œë“œ

- ê¸°ì¡´ì˜ git clone ëª…ë ¹ì–´ë¡œ ë‹¤ìš´ë°›ìœ¼ë©´ ì•„ë§ˆ ìµœì‹ ë²„ì „ìœ¼ë¡œ ë°›ì•„ì§€ëŠ”ë“¯...?  



â—models-r1.13.0 ë‹¤ìš´ ì´ìŠˆâ—

- git cloneìœ¼ë¡œ ë‹¤ìš´ë°›ìœ¼ë©´ ë‹¤ë¥¸ ë²„ì „ì´ ë‹¤ìš´ë°›ì•„ì§...

    â‡’ v.1.13.0 release githubì—ì„œ .zipìœ¼ë¡œ ë‹¤ìš´ë°›ì•„ì„œ ...\Tensor\ í´ë”ì— ì €ì¥í•˜ê³  í´ë”ëª… modelsë¡œ ë³€ê²½í•˜ê¸°!  
    
    

### 3. Protobuf ì„¤ì¹˜ ë° ì»´íŒŒì¼

- ê¸°ì¡´ì— ProtobufëŠ” ë‹¤ìš´ë°›ì•„ì„œ í™˜ê²½ë³€ìˆ˜ê¹Œì§€ ì„¤ì •í•œ ìƒíƒœë‹ˆê¹Œ ì»´íŒŒì¼ë§Œ ì‹¤í–‰

```powershell
[...\Tensorflow\models\research]>
protoc object_detection/protos/*.proto --python_out=.
pip install .
```

- research/slim íŒ¨ìŠ¤ë„ í™˜ê²½ë³€ìˆ˜ì— ì €ì¥  

  

### 4. ì„¤ì¹˜ í™•ì¸í•˜ê¸°

```powershell
[...\Tensorflow\models\research\object_detection]>
jupyter notebook
```

- object_detection_tutorial.ipynb íŒŒì¼ ì‹¤í–‰

- ëª¨ë“  ì½”ë“œ ì‹¤í–‰í•˜ê¸°  

  

**â—11ë²ˆì§¸ ì½”ë“œ ì˜¤ë¥˜ ì´ìŠˆâ—**

- 11ë²ˆì§¸ ì½”ë“œ ì²« ë²ˆì§¸ ì¤„ì— `%matplotlib inline` ì¶”ê°€í•˜ê¸°

![README_assets/Untitled%202.png](README_assets/Untitled%202.png)

- ê·¸ë˜ë„ ì˜¤ë¥˜ë‚˜ë©´ CUDA, CuDNN ë¡œì»¬ í™˜ê²½ì— ì„¤ì¹˜í•˜ê¸° `pick`

[Installation - TensorFlow 2 Object Detection API tutorial documentation](https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/tensorflow-1.14/install.html#tensorflow-gpu)  



### 5. labelImg ì´ìš©í•´ì„œ ì´ë¯¸ì§€ ë¼ë²¨ë§

- labelImg ì„¤ì¹˜

    ```powershell
    pip install labelImg
    ```

      

- ì´ë¯¸ì§€ ë¼ë²¨ë§ ì²˜ë¦¬

    ```powershell
    [...\Object-Detection]>
    labelImg ./images[ë¼ë²¨ë§ í•  ì´ë¯¸ì§€ê°€ ìˆëŠ” ê²½ë¡œ]/

    >> .xml ì €ì¥í•  í´ë” ì„ íƒ(Change Save Dir) 
    >> ë¼ë²¨ë§ í•  ì´ë¯¸ì§€ ìˆëŠ” í´ë” ì„ íƒ(Open Dir) 
    >> ë¼ë²¨ë§ ì²˜ë¦¬

    1. w : ì˜ì—­ ì¡ê¸°
    2. a : ì´ì „ ì‚¬ì§„ìœ¼ë¡œ ì´ë™
    3. d : ë‹¤ìŒ ì‚¬ì§„ìœ¼ë¡œ ì´ë™
    ```

  

### 6. ë¼ë²¨ ë§µ ìƒì„±í•˜ê¸°

- workspace í´ë” ìƒì„±

    ```powershell
    TensorFlow
    â”œâ”€ addons (option) -> ë‚˜ëŠ” ìƒì„± X (pipë¡œ ì„¤ì¹˜í•¨)
    â”‚   â””â”€ labelImg
    â”œâ”€ models
    â”‚   â”œâ”€ official
    â”‚   â”œâ”€ research
    â”‚   â”œâ”€ samples
    â”‚   â””â”€ tutorials
    â””â”€ workspace `new!`
        â””â”€ training_demo `new!`
    				â”œâ”€ annotations : *.csv ë˜ëŠ” *.record íŒŒì¼ ì €ì¥í•˜ëŠ” í´ë”
    				â”œâ”€ images : test, train ì´ë¯¸ì§€, .xml ë°ì´í„° ì €ì¥í•˜ëŠ” í´ë”
    				â”‚   â”œâ”€ test
    				â”‚   â””â”€ train
    				â”œâ”€ pre-trained-model : ì„ íƒí•œ ì‚¬ì „ í›ˆë ¨ ëœ ëª¨ë¸ì´ í¬í•¨ë˜ë©° í›ˆë ¨ ì‘ì—…ì˜ ì‹œì‘ ì²´í¬ í¬ì¸íŠ¸ë¡œ ì‚¬ìš©
    				â”œâ”€ training : í•™ìŠµ ëª¨ë¸ ë° í•™ìŠµ íŒŒì´í”„ ë¼ì¸ êµ¬ì„± íŒŒì¼ ì €ì¥
    				â””â”€ README.md : í•™ìŠµ ê¸°ë¡ ë‚¨ê¸°ê¸°ìš©
    ```

      

- ì´ë¯¸ì§€ ë¶„í• í•˜ê¸°(train, test ë°ì´í„° ë‚˜ëˆ„ê¸°)

    [Training Custom Object Detector - TensorFlow 2 Object Detection API tutorial documentation](https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/tensorflow-1.14/training.html)

    ```python
    """ usage: partition_dataset.py [-h] [-i IMAGEDIR] [-o OUTPUTDIR] [-r RATIO] [-x]
    
    Partition dataset of images into training and testing sets
    
    optional arguments:
      -h, --help            show this help message and exit
      -i IMAGEDIR, --imageDir IMAGEDIR
                            Path to the folder where the image dataset is stored. If not specified, the CWD will be used.
      -o OUTPUTDIR, --outputDir OUTPUTDIR
                            Path to the output folder where the train and test dirs should be created. Defaults to the same directory as IMAGEDIR.
      -r RATIO, --ratio RATIO
                            The ratio of the number of test images over the total number of images. The default is 0.1.
      -x, --xml             Set this flag if you want the xml annotation files to be processed and copied over.
    """
    import os
    import re
    import shutil
    from PIL import Image
    from shutil import copyfile
    import argparse
    import glob
    import math
    import random
    import xml.etree.ElementTree as ET
    
    def iterate_dir(source, dest, ratio, copy_xml):
        source = source.replace('\\', '/')
        dest = dest.replace('\\', '/')
        train_dir = os.path.join(dest, 'train')
        test_dir = os.path.join(dest, 'test')
    
        if not os.path.exists(train_dir):
            os.makedirs(train_dir)
        if not os.path.exists(test_dir):
            os.makedirs(test_dir)
    
        images = [f for f in os.listdir(source)
                  if re.search(r'([a-zA-Z0-9\s_\\.\-\(\):])+(.jpg|.jpeg|.png)$', f)]
    
        num_images = len(images)
        num_test_images = math.ceil(ratio*num_images)
    
        for i in range(num_test_images):
            idx = random.randint(0, len(images)-1)
            filename = images[idx]
            copyfile(os.path.join(source, filename),
                     os.path.join(test_dir, filename))
            if copy_xml:
                xml_filename = os.path.splitext(filename)[0]+'.xml'
                copyfile(os.path.join(source, xml_filename),
                         os.path.join(test_dir,xml_filename))
            images.remove(images[idx])
    
        for filename in images:
            copyfile(os.path.join(source, filename),
                     os.path.join(train_dir, filename))
            if copy_xml:
                xml_filename = os.path.splitext(filename)[0]+'.xml'
                copyfile(os.path.join(source, xml_filename),
                         os.path.join(train_dir, xml_filename))
    
    def main():
    
        # Initiate argument parser
        parser = argparse.ArgumentParser(description="Partition dataset of images into training and testing sets",
                                         formatter_class=argparse.RawTextHelpFormatter)
        parser.add_argument(
            '-i', '--imageDir',
            help='Path to the folder where the image dataset is stored. If not specified, the CWD will be used.',
            type=str,
            default=os.getcwd()
        )
        parser.add_argument(
            '-o', '--outputDir',
            help='Path to the output folder where the train and test dirs should be created. '
                 'Defaults to the same directory as IMAGEDIR.',
            type=str,
            default=None
        )
        parser.add_argument(
            '-r', '--ratio',
            help='The ratio of the number of test images over the total number of images. The default is 0.1.',
            default=0.1,
            type=float)
        parser.add_argument(
            '-x', '--xml',
            help='Set this flag if you want the xml annotation files to be processed and copied over.',
            action='store_true'
        )
        args = parser.parse_args()
    
        if args.outputDir is None:
            args.outputDir = args.imageDir
    
        # Now we are ready to start the iteration
        iterate_dir(args.imageDir, args.outputDir, args.ratio, args.xml)
    
    if __name__ == '__main__':
        main()
    ```

    - í•´ë‹¹ ì½”ë“œë¥¼ `partition_dataset.py` íŒŒì¼ë¡œ ìƒì„±í•˜ê³ , training_damo\images ì•ˆì— ìˆëŠ” ì´ë¯¸ì§€ íŒŒì¼ê³¼ .xmlíŒŒì¼ì„ train, test í´ë”ë¡œ ë‚˜ëˆ” (90%, 10% ë¹„ìœ¨)

        ```powershell
        [..\workspace\training_demo]>
        python partition_dataset.py -x -i ./images -r 0.1
        ```

      

- ë¼ë²¨ ë§µ ìƒì„±(.pbtxt íŒŒì¼ ìƒì„±) â‡’ `training_demo\annotations` í´ë” ì•ˆì— `label_map.pbtxt` ìƒì„±

    ```powershell
    item {
        id: 1
        name: 'avante2020'
    }

    item {
        id: 2
        name: 'granduer2020'
    }

    item {
        id: 3
        name: 'sonata2020'
    }

    .
    .
    .
    ```

  

### 7. TensorFlow Record ë§Œë“¤ê¸°

- scripts í´ë” ìƒì„±

    ```powershell
    TensorFlow
    â”œâ”€ addons
    â”‚   â””â”€ labelImg
    â”œâ”€ models
    â”‚   â”œâ”€ official
    â”‚   â”œâ”€ research
    â”‚   â”œâ”€ samples
    â”‚   â””â”€ tutorials
    â”œâ”€ scripts `new!`
    â”‚   â””â”€ preprocessing `new!`
    â””â”€ workspace
        â””â”€ training_demo
    ```

      

- pandas ì„¤ì¹˜

    ```powershell
    conda install pandas
    ```

      

- `.xml` íŒŒì¼ë¡œ `.csv` íŒŒì¼ ë§Œë“¤ê¸°

    ```powershell
    """
    Usage:
    # Create train data:
    python xml_to_csv.py -i [PATH_TO_IMAGES_FOLDER]/train -o [PATH_TO_ANNOTATIONS_FOLDER]/train_labels.csv
    
    # Create test data:
    python xml_to_csv.py -i [PATH_TO_IMAGES_FOLDER]/test -o [PATH_TO_ANNOTATIONS_FOLDER]/test_labels.csv
    """
    
    import os
    import glob
    import pandas as pd
    import argparse
    import xml.etree.ElementTree as ET
    
    def xml_to_csv(path):
        """Iterates through all .xml files (generated by labelImg) in a given directory and combines them in a single Pandas datagrame.
    
        Parameters:
        ----------
        path : {str}
            The path containing the .xml files
        Returns
        -------
        Pandas DataFrame
            The produced dataframe
        """
    
        xml_list = []
        for xml_file in glob.glob(path + '/*.xml'):
            tree = ET.parse(xml_file)
            root = tree.getroot()
            for member in root.findall('object'):
                value = (root.find('filename').text,
                        int(root.find('size')[0].text),
                        int(root.find('size')[1].text),
                        member[0].text,
                        int(member[4][0].text),
                        int(member[4][1].text),
                        int(member[4][2].text),
                        int(member[4][3].text)
                        )
                xml_list.append(value)
        column_name = ['filename', 'width', 'height',
                    'class', 'xmin', 'ymin', 'xmax', 'ymax']
        xml_df = pd.DataFrame(xml_list, columns=column_name)
        return xml_df
    
    def main():
        # Initiate argument parser
        parser = argparse.ArgumentParser(
            description="Sample TensorFlow XML-to-CSV converter")
        parser.add_argument("-i",
                            "--inputDir",
                            help="Path to the folder where the input .xml files are stored",
                            type=str)
        parser.add_argument("-o",
                            "--outputFile",
                            help="Name of output .csv file (including path)", type=str)
        args = parser.parse_args()
    
        if(args.inputDir is None):
            args.inputDir = os.getcwd()
        if(args.outputFile is None):
            args.outputFile = args.inputDir + "/labels.csv"
    
        assert(os.path.isdir(args.inputDir))
    
        xml_df = xml_to_csv(args.inputDir)
        xml_df.to_csv(
            args.outputFile, index=None)
        print('Successfully converted xml to csv.')
    
    if __name__ == '__main__':
        main()
    ```

    - í•´ë‹¹ ì½”ë“œë¡œ `scripts\preprocessing` í´ë”ì— `xml_to_csv.py` íŒŒì¼ ìƒì„± >> csv íŒŒì¼ ìƒì„±

        ```powershell
        [..\scripts\preprocessing]>
        # train data.csv
        python xml_to_csv.py -i [..\training_demo\images]\train -o [..\training_demo\annotations]\train_labels.csv

        # test data.csv
        python xml_to_csv.py -i [..\training_demo\images]\test -o [..\training_demo\annotations]\test_labels.csv
        ```

      

- `.csv` íŒŒì¼ `.record` íŒŒì¼ë¡œ ë³€í™˜

    ```powershell
    """
    Usage:

    # Create train data:
    python generate_tfrecord.py --label=<LABEL> --csv_input=<PATH_TO_ANNOTATIONS_FOLDER>/train_labels.csv  --output_path=<PATH_TO_ANNOTATIONS_FOLDER>/train.record

    # Create test data:
    python generate_tfrecord.py --label=<LABEL> --csv_input=<PATH_TO_ANNOTATIONS_FOLDER>/test_labels.csv  --output_path=<PATH_TO_ANNOTATIONS_FOLDER>/test.record
    """

    from __future__ import division
    from __future__ import print_function
    from __future__ import absolute_import

    import os
    import io
    import pandas as pd
    import tensorflow as tf
    import sys
    sys.path.append("../../models/research")

    from PIL import Image
    from object_detection.utils import dataset_util
    from collections import namedtuple, OrderedDict

    flags = tf.app.flags
    flags.DEFINE_string('csv_input', '', 'Path to the CSV input')
    flags.DEFINE_string('output_path', '', 'Path to output TFRecord')
    flags.DEFINE_string('label', '', 'Name of class label')
    # if your image has more labels input them as
    # flags.DEFINE_string('label0', '', 'Name of class[0] label')
    # flags.DEFINE_string('label1', '', 'Name of class[1] label')
    # and so on.
    flags.DEFINE_string('img_path', '', 'Path to images')
    FLAGS = flags.FLAGS

    # TO-DO replace this with label map
    # for multiple labels add more else if statements
    def class_text_to_int(row_label):
        if row_label == FLAGS.label:  # 'ship':
            return 1
        # comment upper if statement and uncomment these statements for multiple labelling
        # if row_label == FLAGS.label0:
        #   return 1
        # elif row_label == FLAGS.label1:
        #   return 0
        else:
            None

    def split(df, group):
        data = namedtuple('data', ['filename', 'object'])
        gb = df.groupby(group)
        return [data(filename, gb.get_group(x)) for filename, x in zip(gb.groups.keys(), gb.groups)]

    def create_tf_example(group, path):
        with tf.gfile.GFile(os.path.join(path, '{}'.format(group.filename)), 'rb') as fid:
            encoded_jpg = fid.read()
        encoded_jpg_io = io.BytesIO(encoded_jpg)
        image = Image.open(encoded_jpg_io)
        width, height = image.size

        filename = group.filename.encode('utf8')
        image_format = b'jpg'
        # check if the image format is matching with your images.
        xmins = []
        xmaxs = []
        ymins = []
        ymaxs = []
        classes_text = []
        classes = []

        for index, row in group.object.iterrows():
            xmins.append(row['xmin'] / width)
            xmaxs.append(row['xmax'] / width)
            ymins.append(row['ymin'] / height)
            ymaxs.append(row['ymax'] / height)
            classes_text.append(row['class'].encode('utf8'))
            classes.append(class_text_to_int(row['class']))

        tf_example = tf.train.Example(features=tf.train.Features(feature={
            'image/height': dataset_util.int64_feature(height),
            'image/width': dataset_util.int64_feature(width),
            'image/filename': dataset_util.bytes_feature(filename),
            'image/source_id': dataset_util.bytes_feature(filename),
            'image/encoded': dataset_util.bytes_feature(encoded_jpg),
            'image/format': dataset_util.bytes_feature(image_format),
            'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),
            'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),
            'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),
            'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),
            'image/object/class/text': dataset_util.bytes_list_feature(classes_text),
            'image/object/class/label': dataset_util.int64_list_feature(classes),
        }))
        return tf_example

    def main(_):
        writer = tf.python_io.TFRecordWriter(FLAGS.output_path)
        path = os.path.join(os.getcwd(), FLAGS.img_path)
        examples = pd.read_csv(FLAGS.csv_input)
        grouped = split(examples, 'filename')
        for group in grouped:
            tf_example = create_tf_example(group, path)
            writer.write(tf_example.SerializeToString())

        writer.close()
        output_path = os.path.join(os.getcwd(), FLAGS.output_path)
        print('Successfully created the TFRecords: {}'.format(output_path))

    if __name__ == '__main__':
        tf.app.run()
    ```

    - í•´ë‹¹ ì½”ë“œë¡œ `scripts\preprocessing` í´ë”ì— `generate_tfrecord.py` íŒŒì¼ ìƒì„± >> record íŒŒì¼ë¡œ ë³€í™˜

        ```powershell
        [..\scripts\preprocessing]>
        # Create train data:
        python generate_tfrecord.py --csv_input=[..\training_demo\annotations]/train_labels.csv
        --img_path=[..\training_demo\images]/train  --output_path=[..\training_demo\annotations]/train.record

        # Create test data:
        python generate_tfrecord.py --csv_input=[..\training_demo\annotations]/test_labels.csv
        --img_path=[..\training_demo\images]/test
        --output_path=[..\training_demo\annotations]/test.record
        ```

  

### 8. Learning Pipe-Line êµ¬ì„±í•˜ê¸°

- í•™ìŠµì— ì‚¬ìš©í•  ëª¨ë¸ ê³¨ë¼ì„œ ë‹¤ìš´ë¡œë“œ í•˜ê¸°(ssd_inception_v2_coco ê¸°ì¤€)

    [tensorflow/models](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf1_detection_zoo.md)

    - ì›í•˜ëŠ” ëª¨ë¸ ì„ íƒí•´ì„œ ë‹¤ìš´  

      

    **â—ë‹¤ìš´ë¡œë“œ ì´ìŠˆâ—**

    - ëª¨ë¸ëª…ì„ í´ë¦­í•´ë„ ë‹¤ìš´ë¡œë“œê°€ ì•ˆë¨ â‡’ ëª¨ë¸ ëª…ì— ë§ˆìš°ìŠ¤ì˜¤ë²„ í–ˆì„ ë•Œ, ì¢Œì¸¡ í•˜ë‹¨ì— ë‚˜ì˜¤ëŠ” ë§í¬ë¥¼ ì£¼ì†Œì°½ì— ì§ì ‘ ì…ë ¥
    
    ```powershell
https://download.tensorflow.org/models/object_detection/[ì›í•˜ëŠ” ëª¨ë¸ëª…].tar.gz
    ```

    - ë‹¤ìš´ë°›ì€ .tar.gz íŒŒì¼ì„ `..\training_demo\pre-trained-model` íŒŒì¼ì— ì••ì¶• í•´ì œ
    
        ```powershell
        [..\training_demo\pre-trained-model]>
    tar -xzvf ssd_mobilenet_v1_coco.tar.gz
        ```

    - ëª¨ë¸.config íŒŒì¼ ë‹¤ìš´ë°›ê¸° â‡’ `..\models\research\object_detection\samples\configs` ì—ì„œ ì›í•˜ëŠ” ëª¨ë¸ì˜ .config íŒŒì¼ì„ ë³µì‚¬í•´ì„œ `..\training_demo\training` í´ë”ì— ë¶™ì—¬ë„£ê¸°

    - .config íŒŒì¼ ì„¤ì • ë³€ê²½
    
        ```powershell
        model {
            ssd {
                **num_classes: 1** # Set this to the number of different label classes
                box_coder {
                    faster_rcnn_box_coder {
                        y_scale: 10.0
                        x_scale: 10.0
                        height_scale: 5.0
                        width_scale: 5.0
                }
                }

                ...
    
                }
                feature_extractor {
                    **type: 'ssd_inception_v2'** # Set to the name of your chosen pre-trained model
                    min_depth: 16
                    depth_multiplier: 1.0
                    conv_hyperparams {
                        activation: RELU_6,
                        regularizer {
                            l2_regularizer {
                                weight: 0.00004
                            }
                        }
                        initializer {
                            truncated_normal_initializer {
                                stddev: 0.03
                                mean: 0.0
                            }
                        }
                        batch_norm {
                            train: true,
                            scale: true,
                            center: true,
                            decay: 0.9997,
                            epsilon: 0.001,
                        }
                    }
                    override_base_feature_extractor_hyperparams: true
                }
            
        			...
    
        }
        }
    
        train_config: {
            **batch_size: 12** # Increase/Decrease this value depending on the available memory (Higher values require more memory and vice-versa)
            optimizer {
                rms_prop_optimizer: {
                    learning_rate: {
                        exponential_decay_learning_rate {
                            initial_learning_rate: 0.004
                            decay_steps: 800720
                            decay_factor: 0.95
                        }
                    }
                    momentum_optimizer_value: 0.9
                    decay: 0.9
                    epsilon: 1.0
                }
            }
        **fine_tune_checkpoint: "pre-trained-model/model.ckpt"** # Path to extracted files of pre-trained model
            from_detection_checkpoint: true
    
            # Note: The below line limits the training process to 200K steps, which we
            # empirically found to be sufficient enough to train the pets dataset. This
        # effectively bypasses the learning rate schedule (the learning rate will
            # never decay). Remove the below line to train indefinitely.
    
            **num_steps: 200000** #í•™ìŠµ ë‹¨ê³„ ì„¤ì •(í•´ë‹¹ ë‹¨ê³„ë§Œí¼ í•™ìŠµ ì§„í–‰)
            data_augmentation_options {
                random_horizontal_flip {
                }
            }
            data_augmentation_options {
                ssd_random_crop {
                }
        }
        }
    
        train_input_reader: {
            tf_record_input_reader {
                **input_path: "annotations/train.record"** # Path to training TFRecord file
            }
        **label_map_path: "annotations/label_map.pbtxt"** # Path to label map file
        }
    
        eval_config: {
            # (Optional): Uncomment the line below if you installed the Coco evaluation tools
            # and you want to also run evaluation
            # metrics_set: "coco_detection_metrics"
            # (Optional): Set this to the number of images in your <PATH_TO_IMAGES_FOLDER>/train
            # if you want to also run evaluation
            num_examples: 8000
            # Note: The below line limits the evaluation process to 10 evaluations.
            # Remove the below line to evaluate indefinitely.
        max_evals: 10
        }
    
        eval_input_reader: {
            tf_record_input_reader {
                **input_path: "annotations/test.record"** # Path to testing TFRecord
            }
            **label_map_path: "annotations/label_map.pbtxt"** # Path to label map file
            shuffle: false
            num_readers: 1
    }
        ```

    - slim íŒ¨ìŠ¤ ì„¤ì •
    
        ```powershell
        >> set PYTHONPATH=[..\Tensorflow\models]
        >> set PYTHONPATH=[..\Tensorflow\models\research]
        >> set PYTHONPATH=[..\Tensorflow\models\research\slim]
        ```

  

### 9. Learning Train í•˜ê¸°

- `model_main.py` ë³µì‚¬ â‡’ `..\models\research\object_detection` í´ë”ì— ìˆëŠ” `model_main.py` ë¥¼ ë³µì‚¬í•´ì„œ `..\training_demo` í´ë”ì— ë¶™ì—¬ë„£ê¸°

- ì½”ë“œ ì‹¤í–‰ì‹œí‚¤ê¸°

    ```powershell
    [..\training_demo]>
    python model_main.py --alsologtostderr --train_dir=training/ --pipeline_config_path=training/ssd_inception_v2_coco.config
    ```

  

**â—ì´ìŠˆâ—**

- TypeError 'numpy.float64' ê°€ ë‚˜ëŠ” ê²½ìš°

    â‡’ í•´ë‹¹ íŠœí† ë¦¬ì–¼ ê¸°ì¤€ìœ¼ë¡œ numpy ë²„ì „ì€ 1.16.4ë¡œ ì„¤ì¹˜ë˜ì–´ì•¼ í•˜ëŠ”ë° ì´ ë²„ì „ì´ ì•ˆë§ì•„ì„œ ê·¸ëŸ´ í™•ë¥ ì´ í¬ë‹¤.

    â‡’ matplotlibë¥¼ ì„¤ì¹˜í•˜ë©´ ì €ì ˆë¡œ numpyê°€ ìƒìœ„ ë²„ì „ìœ¼ë¡œ ì„¤ì¹˜ë˜ëŠ”ë° ì´ ë•Œ, matplotlib ë¨¼ì € ì„¤ì¹˜í•˜ê³  numpyë¥¼ 1.16.4ë¡œ ë‹¤ì‹œ ì„¤ì¹˜í•˜ë©´ ìë™ìœ¼ë¡œ ë‹¤ìš´ê·¸ë ˆì´ë“œ ë¨

    â‡’ ì´ ë•Œ, numpyë¥¼ pipë¡œ ì„¤ì¹˜í–ˆìœ¼ë©´ pip uninstall numpy í•´ì•¼ë¨  
    
    

### 10. Exporting a Trained Inference Graph

- `..\Tensorflow\models\research\object_detection` í´ë”ì—ì„œ `export_inference_graph.py` íŒŒì¼ì„ ë³µì‚¬í•´ì„œ `..\training_demo` í´ë”ì— ë¶™ì—¬ë„£ê¸°
- `..\training_demo\training` ì— ìƒì„±ëœ `model.ckpt-*` íŒŒì¼ ì¤‘ ê°€ì¥ ë†’ì€ stepì„ ì²´í¬
- `export_inference_graph.py` ì‹¤í–‰ì‹œí‚¤ê¸°

    ```powershell
    python export_inference_graph.py --input_type image_tensor --pipeline_config_path training/ssd_inception_v2_coco.config --trained_checkpoint_prefix training/model.ckpt-[ìµœìƒìœ„ ë‹¨ê³„] --output_directory trained-inference-graphs/output_inference_graph_v1.pb
    ```

  

### 11. Predict í•´ë³´ê¸°

- `..\training_demo\trained-inference-graphs\output_inference_graph_v1.pd` í´ë” : frozen_inference_graph.pb íŒŒì¼
- `..\training_demo\annotations` í´ë” : label_map.pbtxt
- `..\training_demo\images` í´ë” : test ì´ë¯¸ì§€  
=======
# Object-Detection í•™ìŠµ

## â­GITHUBâ­

[5taku/custom_object_detection](https://github.com/5taku/custom_object_detection/tree/a5921b3c020dddb542412e8c0f38a42e594b34ba#summary)

## Object Detection API ì‚¬ìš©í•´ì„œ ë”°ë¼í•˜ê¸°

### 0. Tutorial

```
Object-Detection Folder
	â””â”€ google-images-download //êµ¬ê¸€ ì´ë¯¸ì§€ í¬ë¡¤ë§
	â””â”€ images //í¬ë¡¤ë§í•œ ì´ë¯¸ì§€ ì €ì¥
	â””â”€ labelImg //ì´ë¯¸ì§€ ë¼ë²¨ë§
	â””â”€ models //tensorflow (ì•„ë§ˆë„)2.0 models Folder
	â””â”€ tensorflow_object_detection_helper_tool //object_detection model api
	â””â”€ xml //ë¼ë²¨ë§ ê²°ê³¼ ì €ì¥
anaconda - Object-Detection
- python 3.7.10

lib
	- cudnn 7.6.5
	- Cython 0.29.22
	- jupyter 1.0.0
	- lxml 4.6.1
	- matplotlib 3.3.4
	- numpy 1.19.2
	- pandas 1.2.3
	- pillow 8.1.2
	- pyqt 5.9.2
	- scikit-learn 0.24.1
	- scipy 1.6.1
	- tensorflow 1.5.0	//2.x ë²„ì „ ì•ˆë¨(tensorflow.contrib.slim ë¬¸ì œ)
	- tqdm 4.56.0
	- etc.
```

### 1. ë°ì´í„° ìˆ˜ì§‘

- Object-Detection / google-images-download ë¥¼ ì´ìš©í•´ì„œ ë°ì´í„° ìˆ˜ì§‘í•˜ê¸°

  (avante2020 ì •/ì¸¡/í›„ë©´ ì´ë¯¸ì§€ ê°ê° 100ì¥ì”© í¬ë¡¤ë§)

```powershell
...\\google-images-download> googleimagesdownload --keywords "avante2020 frontal" --size medium --output_directory ./images/
```

- ì‚¬ì§„ í™•ì¥ìëŠ” .jpgë§Œ ì‚¬ìš© ê°€ëŠ¥(.png/.webp íŒŒì¼ ì‚­ì œ)

- ì ì ˆí•œ ì´ë¯¸ì§€ê°€ ì•„ë‹Œ ì‚¬ì§„ë“¤ ì •ì œ(ì•„ë°˜ë–¼ ì‚¬ì§„ì´ ì•„ë‹Œ ê²ƒ, ì¸¡ë©´ í´ë”ì— ìˆëŠ” í›„ë©´ ì‚¬ì§„ ë“±)

### 2. ë°ì´í„° ë¼ë²¨ë§

- labelImg ì´ìš©í•˜ì—¬ ì´ë¯¸ì§€ì— ë¼ë²¨ë§ ì²˜ë¦¬

```powershell
...\\labelImg> pyrcc5 -o libs/resources.py resources.qrc
...\\labelImg> python labelImg.py -i "../images/ì´ë¯¸ì§€ ì €ì¥ëœ í´ë”ëª…"
```

- Change Save dir â‡’ xml íŒŒì¼ ì €ì¥í•  í´ë” ì§€ì •(ë³´í†µ ì›ë³¸ ì´ë¯¸ì§€ íŒŒì¼í•˜ê³  ê°™ì€ í´ë”ì— ì €ì¥)

- Open Dir â‡’ ì›ë³¸ ì´ë¯¸ì§€ê°€ ì €ì¥ëœ í´ë” ì„ íƒ

- ì›í•˜ëŠ” ì˜ì—­ì„ ì„ íƒí•œ ë’¤, ë¼ë²¨ë§ ì²˜ë¦¬

- ë‹¨ì¶•í‚¤

  - W : ì˜ì—­ ì§€ì •

  - A : ì´ì „ ì´ë¯¸ì§€

  - D : ë‹¤ìŒ ì´ë¯¸ì§€

### 3. label_map.pdtxt íŒŒì¼ ìˆ˜ì •

- ë³¸ì¸ì´ ì§€ì •í•œ ë¼ë²¨ë§ì— ë§ì¶°ì„œ íŒŒì¼ ìˆ˜ì •

**(PATH : ...\tensorflow_object_detection_helper_tool\label_map.pdtxt)**

```
item {
  id: 1
  name: 'avante2020 frontal'
}
item {
  id: 2
  name: 'avante2020 rear'
}
item {
  id: 3
  name: 'avante2020 side'
}
```

### 4. TF RECORD íŒŒì¼ ìƒì„±

- tensorflow_object_detection_helper_tool ì´ìš©í•´ì„œ TF RECORD íŒŒì¼ì„ ìƒì„±

```powershell
...\\tensorflow_object_detection_helper_tool> python tfgenerator.py -i "../images/tfRecord"
```

### 5. Treansfer Learning & exporting

- import ê²½ë¡œ ë§ì¶°ì£¼ê¸°(ì´ìœ ëŠ” ëª¨ë¥´ê² ëŠ”ë° ê²½ë¡œê°€ ì•„ì£¼ ê·¸ëƒ¥ ì—‰ë§ì§„ì°½ì´ì•¼ğŸ¤¬)

- Raster_Rcnn_Inception_v2_coco ëª¨ë¸ì„ í†µí•´ì„œ 50000ë²ˆ í•™ìŠµì‹œí‚¤ê¸°

  (3000ë²ˆ ì£¼ê¸°ë¡œ evaluate ê°’ í™•ì¸)

**â—ì˜¤ë¥˜ ì´ìŠˆâ—**

1. from deployment import model_deploy ê°€ ì–´ë”” ìˆëŠ”ë°....!!!!!!

   â‡’ tf_slim ë”°ë¡œ ì„¤ì¹˜í•´ì„œ í•´ê²°!

   ```
   //cmd ì¼¤ ë•Œë§ˆë‹¤ ì´ê±° ë‘ ì¤„ ì¶”ê°€(ê± ê³ ì •í•˜ëŠ” ë²• ì—†ë‚˜...)
   set PYTHONPATH=C:\\Users\\multicampus\\git\\SSAFY_PJT2\\Object-Detection\\tensorflow\\models;C:\\Users\\multicampus\\git\\SSAFY_PJT2\\Object-Detection\\tensorflow\\models\\research;C:\\Users\\multicampus\\git\\SSAFY_PJT2\\Object-Detection\\tensorflow\\models\\research\\slim

   ...\\tensorflow\\models\\research>>protoc --python_out=. .\\object_detection\\protos\\anchor_generator.proto .\\object_detection\\protos\\argmax_matcher.proto .\\object_detection\\protos\\bipartite_matcher.proto .\\object_detection\\protos\\box_coder.proto .\\object_detection\\protos\\box_predictor.proto .\\object_detection\\protos\\eval.proto .\\object_detection\\protos\\faster_rcnn.proto .\\object_detection\\protos\\faster_rcnn_box_coder.proto .\\object_detection\\protos\\grid_anchor_generator.proto .\\object_detection\\protos\\hyperparams.proto .\\object_detection\\protos\\image_resizer.proto .\\object_detection\\protos\\input_reader.proto .\\object_detection\\protos\\losses.proto .\\object_detection\\protos\\matcher.proto .\\object_detection\\protos\\mean_stddev_box_coder.proto .\\object_detection\\protos\\model.proto .\\object_detection\\protos\\optimizer.proto .\\object_detection\\protos\\pipeline.proto .\\object_detection\\protos\\post_processing.proto .\\object_detection\\protos\\preprocessor.proto .\\object_detection\\protos\\region_similarity_calculator.proto .\\object_detection\\protos\\square_box_coder.proto .\\object_detection\\protos\\ssd.proto .\\object_detection\\protos\\ssd_anchor_generator.proto .\\object_detection\\protos\\string_int_label_map.proto .\\object_detection\\protos\\train.proto .\\object_detection\\protos\\keypoint_box_coder.proto .\\object_detection\\protos\\multiscale_anchor_generator.proto .\\object_detection\\protos\\graph_rewriter.proto
   ```

   [ì°¸ê³ ]

   - ë‚´ì¼ ì‹œë„í•´ë³´ê¸°

   [Tensorflow2 Object Detection API ì„¤ì¹˜ ë° í™˜ê²½ êµ¬ì„±](https://like-edp.tistory.com/10)

   https://deeplearning.home.blog/2018/11/13/python-tensorflow-object-detection-api%EB%A5%BC-%EC%9D%B4%EC%9A%A9%ED%95%9C-%EA%B0%9D%EC%B2%B4-%ED%83%90%EC%A7%80-%EB%B0%A9%EB%B2%95-1/

   [Tf Slim :: Anaconda.org](https://anaconda.org/conda-forge/tf_slim)

   +) train.py / trainer.py íŒŒì¼ì„ ë‘˜ ë‹¤ tensorflow/models/research í´ë”ì— ë³µì‚¬í•´ì¤Œ

## â­ì°¸ê³ ìë£Œâ­

[13. Object Detection - two stage method(R-CNN, fast R-CNN, faster R-CNN)](https://nittaku.tistory.com/273)

[[Object Detection\] 1. Object Detection ë…¼ë¬¸ íë¦„ ë° ë¦¬ë·°](https://nuggy875.tistory.com/20)

[[Object Detection\] 2. R-CNN : ë”¥ëŸ¬ë‹ì„ ì´ìš©í•œ ì²« 2-stage Detector](https://nuggy875.tistory.com/21)
